{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breaking News, World News & Multimedia - The New York Times\n",
      "Here’s what you need to know at the end of the day.\n",
      "How El Chapo ended up in a Brooklyn courtroom.\n",
      "Solve this bite-sized puzzle in just a few minutes.\n",
      "As she aims to lead the House again, Ms. Pelosi will have to navigate between a rampaging president and her colleagues’ plans for fighting back.\n",
      "The finding by a White House review raises the stakes on congressional oversight hearings that the new Democratic House majority will hold.\n",
      "If he wants a unified Senate, Mr. McConnell would be smart to pass criminal justice reform.\n",
      "President Trump is trying to wear down America with childish name-calling. Let’s not fall for it.\n",
      "Locals, known as porteños, take their drinking traditions — and the amazing variety of places where they can indulge them — very seriously.\n",
      "Sweden is one of Europe’s least religious countries. Pastors there are using pop and rock music at Masses to try to attract a younger crowd.\n",
      "A stranger comes to the rescue in a small emergency, a secret told in a taxi and more reader tales of New York City in this week’s Metropolitan Diary.\n",
      "We’d like your thoughts on the New York Times home page experience.Let us know what you think \n"
     ]
    }
   ],
   "source": [
    "#Excercise 17: https://www.practicepython.org/exercise/2014/06/06/17-decode-a-web-page.html \n",
    "#Decode a web: This is the first 4-chili exercise of this blog! We’ll see what people think, and decide whether or not \n",
    "#to continue with 4-chili exercises in the future.\n",
    "#Use the BeautifulSoup and requests  => This is for web scraping...\n",
    "#Python packages to print out a list of all the article titles on the New York Times homepage.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4 as bs    ##beautifulsoup4 as bs\n",
    "import urllib.request  ##urllib module: https://docs.python.org/3/library/urllib.html  =>request is to open and read URL\n",
    "source = urllib.request.urlopen('https://www.nytimes.com/').read()   ##you get source code from here.\n",
    "\n",
    "soup =bs.BeautifulSoup(source,'lxml')   #lxml is the most feature-rich and easy-to-use library for processing XML and HTML in the Python language.\n",
    "\n",
    "#print(soup)\n",
    "#print(soup.title)\n",
    "for paragraph in soup.find_all('title'):\n",
    "    print(paragraph.text)\n",
    "for paragraph in soup.find_all('p'):\n",
    "    print(paragraph.text)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
